{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2025 50Hertz Transmission GmbH and Elia Transmission Belgium\n",
    "#\n",
    "# This Source Code Form is subject to the terms of the Mozilla Public License, v. 2.0.\n",
    "# If a copy of the MPL was not distributed with this file,\n",
    "# you can obtain one at https://mozilla.org/MPL/2.0/.\n",
    "# Mozilla Public License, version 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: Topology optimization of a small grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline consists of three main stages:\n",
    "\n",
    "1. **Data Importing and Preprocessing**  \n",
    "    This stage involves loading your grid data and preparing it for optimization. Preprocessing may include cleaning the data, handling unsupported elements, and performing calculations such as busbar outage analysis.\n",
    "\n",
    "2. **DC Optimization**  \n",
    "    In this stage, the pipeline runs optimization (Map Elites) algorithm using GPU accelerated DC Load flow solver on the preprocessed grid data. The optimizer uses specified metrics and parameters to search for optimal grid topologies or configurations.\n",
    "\n",
    "3. **AC Validation**  \n",
    "    After optimization, the best solutions are validated using AC (Alternating Current) power flow analysis to ensure feasibility and performance under more realistic conditions.\n",
    "\n",
    "---\n",
    "\n",
    "Before running the pipeline on your data, you need to configure the following:\n",
    "\n",
    "1. **PipelineConfig**  \n",
    "    Define the experiment name (`iteration_name`) and the grid file name (`file_name`). The experiment name determines the folder where results and intermediate files are stored. The grid file should be placed inside this folder and can be in formats such as `.xiidm`, `.json` (for PandaPower), or `.zip` (for CGMES).\n",
    "\n",
    "    Note that a folder named 'iteration_name' should be created inside the 'data' folder and the grid file named 'file_name' should be put inside the 'iteration_name' folder.\n",
    "\n",
    "2. **Importer Config**  \n",
    "    Set parameters for importing the grid data, such as area settings and other options relevant to your data source. This configuration ensures that the importer correctly interprets and processes your grid file.\n",
    "\n",
    "3. **Preprocessing Parameters**  \n",
    "    Specify options for the preprocessing step, which are independent of the data source. For example, you can enable or disable preprocessing for busbar outage calculations or set limits for action sets.\n",
    "\n",
    "4. **DC Optimization Configuration (`dc_optimization_cfg`)**  \n",
    "    Define the parameters for the optimizer and loadflow solver. This includes settings such as which metrics to use in the objective function, runtime limits, the number of worst contingencies to consider, and other optimizer-specific options.\n",
    "\n",
    "---\n",
    "\n",
    "**Workflow Summary:**\n",
    "\n",
    "- Set up the required configurations as described above.\n",
    "- Run the pipeline to import, preprocess, and optimize your grid data.\n",
    "- Optionally, rerun the optimization with different parameters without repeating preprocessing or optimisation.\n",
    "- Validate the optimized solutions using AC power flow analysis.\n",
    "\n",
    "This modular approach allows you to efficiently experiment with different configurations and optimization strategies while minimizing redundant computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toop_engine_topology_optimizer.benchmark.benchmark_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Reminder:**  \n",
    "> Create a folder named `iteration_name` inside the `data` folder, and place the grid file named `file_name` inside the `iteration_name` folder.  \n",
    ">  \n",
    "> For example:  \n",
    "> ```\n",
    "> data/\n",
    "> └── <iteration_name>/\n",
    ">     └── <file_name>\n",
    "> ```\n",
    "\n",
    "The data folder already exists in the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up pipeline configuration. Here iteration_name corresponds to the name of the experiment. For example, \"test_tso\". This folder has to be created inside the \"data\" folder. This folder is supposed to contain the grid file specified in file_name.\n",
    "# file_name corresponds to the name of the grid file. This file has to be present inside the folder specified by iteration_name. This folder can have grid data from multiple timesteps.\n",
    "# The grid file can be in any of the supported formats: .xiidm, .json, .mat, .zip (in case of cgmes)\n",
    "\n",
    "iteration_name = \"\"\n",
    "file_name = \"grid.xiidm\"\n",
    "\n",
    "pipeline_cfg = PipelineConfig(\n",
    "    root_path=Path(\"../data/grid_node_breaker\"),\n",
    "    iteration_name = iteration_name,\n",
    "    file_name = file_name,\n",
    "    grid_type=\"powsybl\")\n",
    "\n",
    "# Set up dc_optimisation_configs\n",
    "iteration_path, file_path, data_folder, optimizer_snapshot_dir = get_paths(pipeline_cfg)\n",
    "static_information_file = data_folder / pipeline_cfg.static_info_relpath\n",
    "\n",
    "# Example configuration for the optimizer\n",
    "# Note that this is a minimal example; adjust as needed.\n",
    "# Look at topology_optimizer.interfaces.messages.dc_params.BatchedMEParameters and topology_optimizer.interfaces.messages.dc_params.LoadflowSolverParameters for options.\n",
    "# The values for these configuration classes are set in the \"lf_config\" and \"ga_config\" sections below.\n",
    "dc_optimization_cfg = DictConfig({\n",
    "    \"task_name\": \"test\",\n",
    "    \"fixed_files\": [str(static_information_file)],\n",
    "    \"double_precision\": None,\n",
    "    \"tensorboard_dir\": str(iteration_path) + \"/results/{task_name}\",\n",
    "    \"stats_dir\": str(iteration_path) + \"/results/{task_name}\",\n",
    "    \"summary_frequency\": None,\n",
    "    \"checkpoint_frequency\": None,\n",
    "    \"stdout\": None,\n",
    "    \"double_limits\": None,\n",
    "    \"num_cuda_devices\": 1,\n",
    "    \"omp_num_threads\": 1,\n",
    "    \"xla_force_host_platform_device_count\": None,\n",
    "    \"output_json\": str(iteration_path) + \"/results/output.json\",\n",
    "    \"lf_config\": {\"distributed\": False},\n",
    "    \"ga_config\": {\n",
    "        \"runtime_seconds\": 30,\n",
    "        \"me_descriptors\": [{\"metric\": \"split_subs\", \"num_cells\": 10}],\n",
    "        \"observed_metrics\": [\"overload_energy_n_1\", \"split_subs\"],\n",
    "        \"n_worst_contingencies\": 2\n",
    "    },\n",
    "})\n",
    "ac_validation_cfg = DictConfig({\n",
    "    \"n_processes\": 1,\n",
    "    \"k_best_topos\": 5\n",
    "})\n",
    "\n",
    "logger.info(\"Preparing importer parameters...\")\n",
    "importer_parameters = prepare_importer_parameters(\n",
    "    file_path,\n",
    "    data_folder)\n",
    "# Set cutoff_voltage to an appropriate level to include all voltage levels in the optimization\n",
    "importer_parameters.area_settings.cutoff_voltage = 10 # in kV\n",
    "\n",
    "logger.info(\"Setting up preprocessing parameters...\")\n",
    "preprocessing_parameters = PreprocessParameters(\n",
    "    action_set_clip=2**10,\n",
    "    enable_bb_outage=True,\n",
    "    bb_outage_as_nminus1=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "try:\n",
    "    topo_path = run_pipeline(pipeline_cfg=pipeline_cfg, dc_optim_config=dc_optimization_cfg, ac_validation_cfg=ac_validation_cfg, importer_parameters=importer_parameters, preprocessing_parameters=preprocessing_parameters)\n",
    "    logger.info(f\"Pipeline finished in {time.time() - start:.2f} seconds\")\n",
    "except Exception as exc:\n",
    "    logger.exception(f\"Pipeline failed: {exc}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results generated by the pipeline are organized in a hierarchical folder structure within the experiment directory (e.g., `data/rte/20250220T0830`). This structure is designed to facilitate easy access to all intermediate and final outputs of the optimization and validation process.\n",
    "\n",
    "---\n",
    "\n",
    "### **Folder Structure Overview**\n",
    "\n",
    "```\n",
    "data/\n",
    "└── <iteration_name>/                # e.g., rte\n",
    "    |── <file_name_without_ext>/     # e.g., 20250212T0830\n",
    "    |    ├── optimizer_snapshot/\n",
    "    |    │   ├── run_1/\n",
    "    |    │   │   ├── res.json\n",
    "    |    │   │   ├── topology_0/\n",
    "    |    │   │   │   ├── modified_network.xiidm\n",
    "    |    │   │   │   ├── ac_loadflow_results.csv\n",
    "    |    │   │   │   ├── dc_loadflow_results.csv\n",
    "    |    │   │   │   ├── sld\n",
    "    |    │   │   │   │   ├── sld_split_station_1.png\n",
    "    |    │   │   │   │   ├── sld_split_station_2.png\n",
    "    |    │   │   │   │   └── ...\n",
    "    |    │   │   ├── topology_1/\n",
    "    |    │   │   └── ...\n",
    "    |    │   └── ...\n",
    "    |    ├── run_2/\n",
    "    |    │   └── ...\n",
    "    |    └── ...\n",
    "    |    └── ...\n",
    "    └── results/\n",
    "        └── task_name/\n",
    "            └── ...\n",
    "```\n",
    "#### **optimizer_snapshot/**\n",
    "- This folder contains the results of all optimization runs for the given experiment.\n",
    "- Each optimization run is stored in a separate subfolder (e.g., `run_1`, `run_2`, etc.). The names of these folders correspond to different executions of the optimizer, which may vary based on parameters or random seeds.\n",
    "\n",
    "#### **optimizer_snapshot/run_{n}/**\n",
    "- Each `run_{n}` folder corresponds to a single execution of the optimizer with a specific configuration.\n",
    "- **res.json**:  \n",
    "  - This file summarizes the results of the optimization run, including metrics, best topologies found, and references to the evaluated topologies.\n",
    "- **topology_{x}/**:  \n",
    "  - Each subfolder represents a specific topology evaluated during the AC validation stage.\n",
    "  - `{x}` is the index of the topology (e.g., `topology_0`, `topology_1`, etc.).\n",
    "\n",
    "#### **optimizer_snapshot/run_{n}/topology_{x}/**\n",
    "- **modified_network.xiidm**:  \n",
    "  - The grid file representing the network after applying the topology changes for this specific solution.\n",
    "- **ac_loadflow_results.csv**:  \n",
    "  - Results of the AC loadflow analysis for this topology containing both the N-0 and N-1 scenarios.\n",
    "- **dc_loadflow_results.csv**:  \n",
    "  - Results of the DC loadflow analysis for this topology.\n",
    "- **sld/{y}_sld.png**:  \n",
    "  - Single line diagrams (SLDs) for substations that were split as part of the topology modification.  \n",
    "  - `{y}` corresponds to the name of the split station.\n",
    "\n",
    "#### **results/task_name/**\n",
    "- This folder is reserved for storing the checkpoint results and also the tensorboard logs for each DC optimisation task, organized by task name. Note that the 'task_name' corresponds to the name of the task defined in the `dc_optimisation_config`.\n",
    "---\n",
    "\n",
    "### **Summary**\n",
    "\n",
    "- **optimizer_snapshot**: Contains all optimization runs.\n",
    "- **run_{n}**: Each run folder contains results for a specific optimizer execution.\n",
    "- **res.json**: Summary of the run and references to topologies.\n",
    "- **topology_{x}**: Contains all files related to a specific evaluated topology, including the modified grid, loadflow results, and diagrams.\n",
    "- **results/task_name**: Contains checkpoint results and logs for each DC optimization task.\n",
    "\n",
    "This structure ensures that all results are logically grouped and easily accessible for further analysis, visualization, or reporting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the results\n",
    "\n",
    "We visualize the changes of the optimized topology by inspecting the single-line diagram of the effected substation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypowsybl as pp\n",
    "from IPython.display import SVG, display\n",
    "\n",
    "# Adjust run directory\n",
    "run_dir = 'run_0'\n",
    "# Find name of the voltage level (substation) that was adjusted\n",
    "# The SLD of the adjusted substation is named as \"<voltage_level_name>_sld.svg\"\n",
    "voltage_level_name = 'VLevel2'\n",
    "sld_path = optimizer_snapshot_dir / run_dir / 'topology_0' / \"sld\" / f\"{voltage_level_name}_sld_initial.svg\"\n",
    "\n",
    "# Load initial grid into pypowsybl\n",
    "network = pp.network.load(str(iteration_name / file_path))\n",
    "# Run AC load flow on initial grid to see flows in SLD\n",
    "pp.loadflow.run_ac(network)\n",
    "\n",
    "# Create SVG of initial grid's SLD for the specified substation\n",
    "svg_initial = get_single_line_diagram_custom(network, 'VL2')\n",
    "sld_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "with open(sld_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(svg_initial._content)\n",
    "\n",
    "# Display SLD before optimization\n",
    "display(SVG(filename=sld_path))\n",
    "# Display SLD after optimization\n",
    "display(SVG(filename=optimizer_snapshot_dir / run_dir / 'topology_0' / \"sld\" / f\"{voltage_level_name}_sld.svg\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the substation `VL2` was split and the busbars have slightly different voltage levels.\n",
    "\n",
    "We can inspect the overload energy before and after the split to see the impact on congestion.\n",
    "This can be done by inspecting the `res.json` in the `run_<number>` directory.\n",
    "The field `overload_energy_n_1` can be found for the `best_topos` and as a member of `initial_metrics`.\n",
    "\n",
    "Check it out yourself to get familiar with the data that the optimizer logs and uses.\n",
    "\n",
    "This concludes the example.\n",
    "We have successfully reduced the overload energy in the grid by performing topological adjustments."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
